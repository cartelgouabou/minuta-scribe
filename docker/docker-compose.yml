services:
  backend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.backend
    container_name: minuta-backend
    ports:
      - "8000:8000"
    env_file:
      - ../backend/.env  # Charger les variables d'environnement depuis backend/.env si présent
    environment:
      - DATABASE_URL=sqlite:///./data/minuta.db
      - OLLAMA_BASE_URL=http://ollama:11434
      # Variables optionnelles pour Groq et Vercel (peuvent être définies dans backend/.env)
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - AI_GATEWAY_API_KEY=${AI_GATEWAY_API_KEY:-}
      - LLM_MODELS=${LLM_MODELS:-}
    volumes:
      - backend_data:/app/backend/data
      # Volume pour développement (commenter en production)
      # - ../backend:/app/backend
    networks:
      - minuta-network
    depends_on:
      ollama:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 180s  # 3 minutes pour laisser le temps au modèle Whisper de se charger

  frontend:
    build:
      context: ..
      dockerfile: docker/Dockerfile.frontend
    container_name: minuta-frontend
    ports:
      - "80:80"
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - minuta-network
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: minuta-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - minuta-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

volumes:
  backend_data:
    driver: local
  ollama_data:
    driver: local

networks:
  minuta-network:
    driver: bridge
